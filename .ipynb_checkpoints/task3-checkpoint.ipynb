{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e31a6645",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'seller_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mmerge(products_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     23\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mmerge(order_reviews_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124morder_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df\u001b[38;5;241m.\u001b[39mmerge(sellers_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseller_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Load BERT model and tokenizer\u001b[39;00m\n\u001b[0;32m     27\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mC:\\Users\\jghhd\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10093\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m  10074\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m  10075\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m  10076\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10089\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10090\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m  10091\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m> 10093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10094\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10095\u001b[0m         right,\n\u001b[0;32m  10096\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m  10097\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m  10098\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m  10099\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m  10100\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m  10101\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m  10102\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m  10103\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m  10104\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m  10105\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m  10106\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10107\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Users\\jghhd\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    111\u001b[0m         left,\n\u001b[0;32m    112\u001b[0m         right,\n\u001b[0;32m    113\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m    114\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m    115\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[0;32m    116\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[0;32m    117\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[0;32m    118\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[0;32m    119\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    120\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[0;32m    121\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[0;32m    122\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    123\u001b[0m     )\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mC:\\Users\\jghhd\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[0;32m    699\u001b[0m (\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[1;32mC:\\Users\\jghhd\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1160\u001b[0m rk \u001b[38;5;241m=\u001b[39m cast(Hashable, rk)\n\u001b[0;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1162\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(rk))\n\u001b[0;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1164\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[0;32m   1165\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\Users\\jghhd\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[0;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1848\u001b[0m     )\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'seller_id'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure device for model computation (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the data\n",
    "orders_df = pd.read_csv('orders.csv')\n",
    "order_reviews_df = pd.read_csv('order_reviews.csv')\n",
    "order_items_df = pd.read_csv('order_items.csv')\n",
    "products_df = pd.read_csv('products.csv')\n",
    "sellers_df = pd.read_csv('sellers.csv')\n",
    "\n",
    "# Merge dataframes\n",
    "merged_df = orders_df.merge(order_items_df, on='order_id')\n",
    "merged_df = merged_df.merge(products_df, on='product_id')\n",
    "merged_df = merged_df.merge(order_reviews_df, on='order_id')\n",
    "merged_df = merged_df.merge(sellers_df, on='seller_id')\n",
    "\n",
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)\n",
    "model = model.to(device)\n",
    "\n",
    "# Predict sentiments function\n",
    "def predict_sentiments(text):\n",
    "    if not text:\n",
    "        return \"Neutral\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=-1)\n",
    "    return {0: \"Negative\", 1: \"Neutral\", 2: \"Positive\"}[prediction.item()]\n",
    "\n",
    "# Apply sentiment analysis\n",
    "merged_df['sentiment'] = merged_df['review_comment_message'].apply(predict_sentiments)\n",
    "\n",
    "# Analyze correlation\n",
    "merged_df['sentiment_score'] = merged_df['sentiment'].map({'Positive': 1, 'Neutral': 0, 'Negative': -1})\n",
    "correlation = merged_df['review_score'].corr(merged_df['sentiment_score'])\n",
    "\n",
    "# Identify products and sellers with extreme reviews\n",
    "extreme_products = merged_df.groupby('product_id')['sentiment_score'].mean().sort_values()\n",
    "extreme_sellers = merged_df.groupby('seller_id')['sentiment_score'].mean().sort_values()\n",
    "\n",
    "# Visualize correlation and distribution\n",
    "sns.heatmap(merged_df[['review_score', 'sentiment_score']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation between Review Scores and Sentiments')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='sentiment', data=merged_df)\n",
    "plt.title('Distribution of Sentiments')\n",
    "plt.show()\n",
    "\n",
    "# Save the results\n",
    "merged_df.to_csv('analyzed_reviews.csv', index=False)\n",
    "\n",
    "print(f\"Sentiment analysis completed. Correlation: {correlation}\")\n",
    "print(\"Results saved and visualized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3e4ddbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolumny orders_df: Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',\n",
      "       'order_approved_at', 'order_delivered_carrier_date',\n",
      "       'order_delivered_customer_date', 'order_estimated_delivery_date'],\n",
      "      dtype='object')\n",
      "Kolumny order_reviews_df: Index(['review_id', 'order_id', 'review_score', 'review_comment_title',\n",
      "       'review_comment_message', 'review_creation_date',\n",
      "       'review_answer_timestamp'],\n",
      "      dtype='object')\n",
      "Kolumny order_items_df: Index(['order_id', 'order_item_id', 'product_id', 'seller_id',\n",
      "       'shipping_limit_date', 'price', 'freight_value'],\n",
      "      dtype='object')\n",
      "Kolumny products_df: Index(['product_id', 'product_category_name', 'product_name_lenght',\n",
      "       'product_description_lenght', 'product_photos_qty', 'product_weight_g',\n",
      "       'product_length_cm', 'product_height_cm', 'product_width_cm'],\n",
      "      dtype='object')\n",
      "Kolumny sellers_df: Index(['seller_id;seller unique identifier'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Kolumny orders_df:\", orders_df.columns)\n",
    "print(\"Kolumny order_reviews_df:\", order_reviews_df.columns)\n",
    "print(\"Kolumny order_items_df:\", order_items_df.columns)\n",
    "print(\"Kolumny products_df:\", products_df.columns)\n",
    "print(\"Kolumny sellers_df:\", sellers_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebed74d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wczytano z domyślnym separatorem (przecinek), kolumny: Index(['seller_id;seller unique identifier'], dtype='object')\n",
      "Wczytano ze średnikiem jako separatorem, kolumny: Index(['seller_id', 'seller unique identifier'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Próba wczytania pliku bez określania separatora (domniemany separator to przecinek)\n",
    "try:\n",
    "    sellers_df_comma = pd.read_csv('sellers.csv')\n",
    "    print(\"Wczytano z domyślnym separatorem (przecinek), kolumny:\", sellers_df_comma.columns)\n",
    "except Exception as e:\n",
    "    print(\"Błąd przy wczytywaniu z separatorem przecinkowym:\", e)\n",
    "\n",
    "# Próba wczytania pliku ze średnikiem jako separatorem\n",
    "try:\n",
    "    sellers_df_semicolon = pd.read_csv('sellers.csv', sep=';')\n",
    "    print(\"Wczytano ze średnikiem jako separatorem, kolumny:\", sellers_df_semicolon.columns)\n",
    "except Exception as e:\n",
    "    print(\"Błąd przy wczytywaniu z separatorem średnikowym:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6143091c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wynik scalenia: Empty DataFrame\n",
      "Columns: [order_id, customer_id, order_status, order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, order_estimated_delivery_date, order_item_id, product_id, seller_id, shipping_limit_date, price, freight_value, product_category_name, product_name_lenght, product_description_lenght, product_photos_qty, product_weight_g, product_length_cm, product_height_cm, product_width_cm, review_id, review_score, review_comment_title, review_comment_message, review_creation_date, review_answer_timestamp, seller unique identifier]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Wczytywanie innych plików danych, jeśli jeszcze tego nie zrobiłeś\n",
    "orders_df = pd.read_csv('orders.csv')\n",
    "order_reviews_df = pd.read_csv('order_reviews.csv')\n",
    "order_items_df = pd.read_csv('order_items.csv')\n",
    "products_df = pd.read_csv('products.csv')\n",
    "\n",
    "# Użycie poprawnie wczytanego sellers_df\n",
    "sellers_df = pd.read_csv('sellers.csv', sep=';')\n",
    "\n",
    "# Scalanie DataFrame'ów\n",
    "merged_df = orders_df.merge(order_items_df, on='order_id')\n",
    "merged_df = merged_df.merge(products_df, on='product_id')\n",
    "merged_df = merged_df.merge(order_reviews_df, on='order_id')\n",
    "merged_df = merged_df.merge(sellers_df, on='seller_id')\n",
    "\n",
    "# Sprawdzenie wyników scalenia\n",
    "print(\"Wynik scalenia:\", merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a5935f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wspólnych seller_id: 0\n"
     ]
    }
   ],
   "source": [
    "# Wypisz unikalne wartości seller_id w obu DataFrame'ach\n",
    "unique_seller_ids_in_items = order_items_df['seller_id'].unique()\n",
    "unique_seller_ids_in_sellers = sellers_df['seller_id'].unique()\n",
    "\n",
    "# Sprawdź, czy istnieją wspólne wartości\n",
    "common_seller_ids = set(unique_seller_ids_in_items) & set(unique_seller_ids_in_sellers)\n",
    "print(f\"Liczba wspólnych seller_id: {len(common_seller_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff03e32b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wynik scalenia po czyszczeniu: Empty DataFrame\n",
      "Columns: [order_id, customer_id, order_status, order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, order_estimated_delivery_date, order_item_id, product_id, seller_id, shipping_limit_date, price, freight_value, product_category_name, product_name_lenght, product_description_lenght, product_photos_qty, product_weight_g, product_length_cm, product_height_cm, product_width_cm, review_id, review_score, review_comment_title, review_comment_message, review_creation_date, review_answer_timestamp, seller unique identifier]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Usuń białe znaki z seller_id w obu DataFrame'ach\n",
    "order_items_df['seller_id'] = order_items_df['seller_id'].str.strip()\n",
    "sellers_df['seller_id'] = sellers_df['seller_id'].str.strip()\n",
    "\n",
    "# Ponowne scalanie\n",
    "merged_df = orders_df.merge(order_items_df, on='order_id')\n",
    "merged_df = merged_df.merge(products_df, on='product_id')\n",
    "merged_df = merged_df.merge(order_reviews_df, on='order_id')\n",
    "merged_df = merged_df.merge(sellers_df, on='seller_id')\n",
    "\n",
    "# Sprawdź wynik scalenia\n",
    "print(\"Wynik scalenia po czyszczeniu:\", merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad686b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowe seller_id z order_items_df: 25021     2f4b9d112bfa44a214bc6cef085d17c8\n",
      "94086     f457c46070d02cadd8a68551231220dd\n",
      "107125    7ddcbb64b5bc1ef36ca8c151f6ec77df\n",
      "96599     0be8ff43f22e456b4e0371b2245e4d01\n",
      "109265    e9bc59e7b60fc3063eb2290deda4cced\n",
      "Name: seller_id, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrzykładowe seller_id z order_items_df:\u001b[39m\u001b[38;5;124m\"\u001b[39m, order_items_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseller_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrzykładowe seller_id z sellers_df:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sellers_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseller_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[1;32mC:\\Users\\jghhd\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:5773\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5771\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[1;32m-> 5773\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39msample(obj_len, size, replace, weights, rs)\n\u001b[0;32m   5774\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   5776\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[1;32mC:\\Users\\jghhd\\anaconda3\\Lib\\site-packages\\pandas\\core\\sample.py:150\u001b[0m, in \u001b[0;36msample\u001b[1;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m random_state\u001b[38;5;241m.\u001b[39mchoice(obj_len, size\u001b[38;5;241m=\u001b[39msize, replace\u001b[38;5;241m=\u001b[39mreplace, p\u001b[38;5;241m=\u001b[39mweights)\u001b[38;5;241m.\u001b[39mastype(\n\u001b[0;32m    151\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    152\u001b[0m )\n",
      "File \u001b[1;32mmtrand.pyx:984\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "print(\"Przykładowe seller_id z order_items_df:\", order_items_df['seller_id'].sample(5))\n",
    "print(\"Przykładowe seller_id z sellers_df:\", sellers_df['seller_id'].sample(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c605bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Przykładowe seller_id z sellers_df: 1               seller_city\n",
      "0    seller_zip_code_prefix\n",
      "2              seller_state\n",
      "Name: seller_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "sample_size = min(5, sellers_df.shape[0])  # Bierzemy albo 5, albo liczbę rekordów, jeśli jest mniejsza niż 5\n",
    "print(\"Przykładowe seller_id z sellers_df:\", sellers_df['seller_id'].sample(sample_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79099514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['seller_id', 'seller unique identifier'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(sellers_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1a63cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tylko jeśli kolumna 'seller_id' faktycznie istnieje po prawidłowym wczytaniu\n",
    "if 'seller_id' in sellers_df.columns:\n",
    "    sellers_df['seller_id'] = sellers_df['seller_id'].str.strip()  # Usuwanie zbędnych spacji\n",
    "else:\n",
    "    print(\"Brak kolumny 'seller_id'. Dostępne kolumny:\", sellers_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4af79508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [order_id, customer_id, order_status, order_purchase_timestamp, order_approved_at, order_delivered_carrier_date, order_delivered_customer_date, order_estimated_delivery_date, order_item_id, product_id, seller_id, shipping_limit_date, price, freight_value, product_category_name, product_name_lenght, product_description_lenght, product_photos_qty, product_weight_g, product_length_cm, product_height_cm, product_width_cm, review_id, review_score, review_comment_title, review_comment_message, review_creation_date, review_answer_timestamp, seller unique identifier]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = orders_df.merge(order_items_df, on='order_id')\n",
    "merged_df = merged_df.merge(products_df, on='product_id')\n",
    "merged_df = merged_df.merge(order_reviews_df, on='order_id')\n",
    "merged_df = merged_df.merge(sellers_df, on='seller_id')\n",
    "\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05df4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
